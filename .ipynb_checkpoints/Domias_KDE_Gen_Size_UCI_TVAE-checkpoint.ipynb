{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : \n",
      "    The default C++ compiler could not be found on your system.\n",
      "    You need to either define the CXX environment variable or a symlink to the g++ command.\n",
      "    For example if g++-8 is the command you can do\n",
      "      import os\n",
      "      os.environ['CXX'] = 'g++-8'\n",
      "    \n",
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sdv.single_table import TVAESynthesizer\n",
    "\n",
    "from domias.evaluator import evaluate_performance\n",
    "from domias.models.generator import GeneratorInterface\n",
    "from domias.models.ctgan import CTGAN\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing, fetch_covtype, load_digits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in UCI dataset\n",
    "df_uci = pd.read_csv(r'C:\\Users\\jordy\\OneDrive\\MSc_Python\\Individual_Project\\Data\\UCI_Credit_Card.csv')\n",
    "\n",
    "#convert dataframe to array\n",
    "arr_uci = np.array(df_uci.iloc[:, 1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data loader\n",
    "def get_dataset() -> np.ndarray:\n",
    "    def data_loader() -> np.ndarray:\n",
    "        scaler = StandardScaler()\n",
    "        X =arr_uci\n",
    "        np.random.shuffle(X)\n",
    "        return scaler.fit_transform(X)\n",
    "\n",
    "    return data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ae2522bf5069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mtraining_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                     \u001b[0msynthetic_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgen_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mdensity_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdensity_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 )\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\domias\\evaluator.py\u001b[0m in \u001b[0;36mevaluate_performance\u001b[1;34m(generator, dataset, mem_set_size, reference_set_size, training_epochs, synthetic_sizes, density_estimator, seed, device, shifted_column, zero_quantile, reference_kept_p)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;31m# Train generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msynthetic_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msynthetic_sizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ae2522bf5069>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_kde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sdv\\single_table\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_state_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mprocessed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sdv\\single_table\\base.py\u001b[0m in \u001b[0;36mfit_processed_data\u001b[1;34m(self, processed_data)\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[0mThe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fitted_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sdv\\single_table\\ctgan.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, processed_data)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mdiscrete_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_discrete_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTVAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiscrete_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconditions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ctgan\\synthesizers\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_states\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ctgan\\synthesizers\\tvae.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, discrete_columns)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 loss_1, loss_2 = _loss_function(\n\u001b[0;32m    171\u001b[0m                     \u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_info_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                 )\n\u001b[0;32m    174\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ctgan\\synthesizers\\tvae.py\u001b[0m in \u001b[0;36m_loss_function\u001b[1;34m(recon_x, x, sigmas, mu, logvar, output_info, factor)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0med\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mspan_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0meq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meq\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_generator(\n",
    "    gan_method: str = \"CTGAN\",\n",
    "    epochs: int = 1000,\n",
    "    seed: int = 0,\n",
    ") -> GeneratorInterface:\n",
    "    class LocalGenerator(GeneratorInterface):\n",
    "        def __init__(self) -> None:\n",
    "            if gan_method == \"TVAE\":\n",
    "                syn_model = TVAESynthesizer(metadata, epochs=epochs)\n",
    "            elif gan_method == \"CTGAN\":\n",
    "                syn_model = CTGAN(epochs=epochs)\n",
    "            elif gan_method == \"KDE\":\n",
    "                syn_model = None\n",
    "            else:\n",
    "                raise RuntimeError()\n",
    "            self.method = gan_method\n",
    "            self.model = syn_model\n",
    "                \n",
    "\n",
    "        def fit(self, data: pd.DataFrame) -> \"LocalGenerator\":\n",
    "            if self.method == \"KDE\":\n",
    "                self.model = stats.gaussian_kde(np.transpose(data))\n",
    "            else:\n",
    "                self.model.fit(data)\n",
    "            return self\n",
    "\n",
    "        def generate(self, count: int) -> pd.DataFrame:\n",
    "            \n",
    "            if gan_method == \"KDE\":\n",
    "                samples = pd.DataFrame(self.model.resample(count).transpose(1, 0))\n",
    "            elif gan_method == \"TVAE\":\n",
    "                samples = self.model.sample(count)\n",
    "            elif gan_method == \"CTGAN\":\n",
    "                samples = self.model.generate(count)\n",
    "            else:\n",
    "                raise RuntimeError()\n",
    "\n",
    "            return samples\n",
    "            \n",
    "            #return self.model.sample(count)\n",
    "\n",
    "    return LocalGenerator()\n",
    "\n",
    "\n",
    "#Loading metadata from dataset for use in TVAESynthesizer\n",
    "dataset = get_dataset()\n",
    "df_dataset = pd.DataFrame(dataset)\n",
    "df_dataset.rename(columns={0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8:'8', 9:'9', 10:'10', 11:'11', 12:'12',\n",
    "                          13:'13', 14:'14', 15:'15', 16:'16', 17:'17', 18:'18', 19:'19', 20:'20', 21:'21', 22:'22', 23:'23'}, inplace = True)\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Args:\n",
    "    generator: GeneratorInterface\n",
    "        Generator with the `fit` and `generate` methods. The generator MUST not be fitted.\n",
    "    dataset: int\n",
    "        The evaluation dataset, used to derive the training and test datasets.\n",
    "    training_size: int\n",
    "        The split for the training (member) dataset out of `dataset`\n",
    "    reference_size: int\n",
    "        The split for the reference dataset out of `dataset`.\n",
    "    training_epochs: int\n",
    "        Training epochs\n",
    "    synthetic_sizes: List[int]\n",
    "        For how many synthetic samples to test the attacks.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "CTGAN Args:\n",
    "\n",
    "embedding_dim: int = 128,\n",
    "generator_dim: Tuple = (256, 256),\n",
    "discriminator_dim: Tuple = (256, 256),\n",
    "generator_lr: float = 2e-4,\n",
    "generator_decay: float = 1e-6,\n",
    "discriminator_lr: float = 2e-4,\n",
    "discriminator_decay: float = 1e-6,\n",
    "batch_size: int = 500,\n",
    "discriminator_steps: int = 1,\n",
    "log_frequency: bool = True,\n",
    "verbose: bool = False,\n",
    "epochs: int = 300,\n",
    "pac: int = 1,\n",
    "cuda: bool = True,\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# mem_set_size = 1000 -> originally what training size was\n",
    "reference_set_size = 10000 #held out set\n",
    "training_epochs = [2000]\n",
    "training_sizes = [10000] #D-mem\n",
    "#synthetic_sizes = [200]\n",
    "density_estimator = \"kde\"  # prior, kde, bnaf\n",
    "#gen_sizes = [100, 200, 500, 1000] #same as synthetic_sizes -> D_syn\n",
    "gen_sizes = [100, 200, 500, 1000, 2000]\n",
    "\n",
    "method = \"TVAE\"\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Set the number of iterations\n",
    "num_iterations = 5\n",
    "\n",
    "for iteration in range(1, num_iterations+1):\n",
    "    # Initialize the result dictionary for the current iteration\n",
    "    iteration_results = {}\n",
    "    \n",
    "    \n",
    "    for gen_size in gen_sizes:\n",
    "        size_results = {}\n",
    "    \n",
    "        for training_size in training_sizes:\n",
    "            # Initialize the result dictionary for the current training size\n",
    "\n",
    "            for training_epoch in training_epochs:\n",
    "                generator = get_generator(\n",
    "                    gan_method=method,\n",
    "                    epochs=training_epoch,\n",
    "                )\n",
    "\n",
    "                perf = evaluate_performance(\n",
    "                    generator,\n",
    "                    dataset,\n",
    "                    training_size,\n",
    "                    reference_set_size,\n",
    "                    training_epochs=training_epoch,\n",
    "                    synthetic_sizes=[gen_size],\n",
    "                    density_estimator=density_estimator,\n",
    "                )\n",
    "\n",
    "                # Store the MIA performance for the current training size and epoch\n",
    "                size_results[training_epoch] = perf[gen_size][\"MIA_performance\"]\n",
    "\n",
    "            # Store the results for the current training size\n",
    "            iteration_results[gen_size] = size_results\n",
    "\n",
    "        # Store the results for the current iteration\n",
    "        results[iteration] = iteration_results\n",
    "\n",
    "# Print the results\n",
    "for iteration, iteration_results in results.items():\n",
    "    print(f\"Iteration {iteration}:\")\n",
    "    for gen_size, size_results in iteration_results.items():\n",
    "        print(f\"Training Size {training_size}:\")\n",
    "        for training_epoch, mia_performance in size_results.items():\n",
    "            print(f\"Training Epoch {training_epoch}: MIA Performance = {mia_performance}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = training_sizes[0]\n",
    "training_epoch = training_epochs[0]\n",
    "reference_set_size = reference_set_size\n",
    "\n",
    "output_gen = pd.DataFrame([], columns=[\"iteration\", \"epoch\", \"training_size\", \"reference_size\", \"gen_size\", \"src\", \"aucroc\"])\n",
    "\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    for gen_size in gen_sizes:\n",
    "        gen_set_size_res = results[iteration][gen_size][training_epoch]\n",
    "        perf = gen_set_size_res  # Assuming perf is the correct value for accuracy\n",
    "\n",
    "        for key in perf:\n",
    "            output_gen = pd.concat(\n",
    "                [\n",
    "                    output_gen,\n",
    "                    pd.DataFrame(\n",
    "                        [\n",
    "                            [iteration, training_epoch, training_size, reference_set_size, gen_size, key, perf[key][\"aucroc\"]]\n",
    "                        ],\n",
    "                        columns=[\"iteration\", \"epoch\", \"training_size\", \"reference_size\", \"gen_size\", \"src\", \"aucroc\"],\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "output_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results df to csv\n",
    "output_gen.to_csv('kde_gen_output_UCI_TVAE_fix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
